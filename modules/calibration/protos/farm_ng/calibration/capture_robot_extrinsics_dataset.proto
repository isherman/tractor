syntax = "proto3";

import "farm_ng/calibration/robot_hal.proto";
import "farm_ng/core/resource.proto";
import "farm_ng/perception/apriltag.proto";
import "farm_ng/perception/camera_model.proto";
import "farm_ng/perception/geometry.proto";

package farm_ng.calibration;
option go_package = "github.com/farm-ng/genproto/calibration";

message CartesianWorkspace {
  // The workspace frame, relative to the base frame of the robot
  farm_ng.perception.NamedSE3Pose base_pose_workspace = 1;

  // The size of the workspace, in meters, along its X, Y, and Z dimensions.
  farm_ng.perception.Vec3 size = 2;
}

// Evenly subdivides a cartesian workspace into a set of axis-aligned poses.
message SampledCartesianWorkspace {
  CartesianWorkspace workspace = 1;

  // The number of evenly-spaced samples to take along the X,Y, and Z dimensions, respectively.
  // The first sample along each dimension is taken at its origin.
  // The second sample along each dimension is taken at the extent of the workspace.
  // Additional samples evenly divide the distance between the origin and the extent.
  //
  // For example, on the unit cube,
  // {sample_count_x: 1, sample_count_y: 2, sample_count_z: 3} would sample:
  // {{0, 0, 0.0}, {0, 1, 0.0},
  //  {0, 0, 0.5}, {0, 1, 0.5},
  //  {0, 0, 1.0}, {0, 1, 1.0}},
  //
  // Values less than 1 default to 1.
  int32 sample_count_x = 2;
  int32 sample_count_y = 3;
  int32 sample_count_z = 4;
}

// Sampling algorithm:
// - For each translation workspace_T_link in the workspace volume:
//   - Find a set of link orientations workspace_R_link that meet the visibility requirements
//   - Emit base_pose_link = base_pose_workspace * compose(workspace_T_link, workspace_R_link)
//
// Visibility algorithm:
// - Set of orientations where the link_tag_rig is visible in each camera in the
//   the base_camera_rig, and also where base_tag_rig is visible from link_camera_rig.
//
// Poses generated by the sampling algorithm are not guaranteed to avoid self-collision, they
// should be validated by the server.
message CaptureRobotExtrinsicsDatasetConfiguration {
  // The dataset name.
  string name = 1;

  // A cartesian volume, sampled in its translation components
  SampledCartesianWorkspace sampled_workspace = 2;

  // The name of the workspace frame
  string workspace_frame_name = 3;

  // The name of the base frame
  string base_frame_name = 4;

  // The name of the link frame
  string link_frame_name = 5;

  // A collection of cameras, rigidly connected to the robot base.
  farm_ng.perception.MultiViewCameraRig base_camera_rig = 6;

  // A collection of cameras, rigidly connected to a robot link.
  farm_ng.perception.MultiViewCameraRig link_camera_rig = 7;

  // A collection of apriltags, rigidly connected to the robot's base.
  farm_ng.perception.ApriltagRig base_tag_rig = 8;

  // A collection of apriltags, rigidly connected to a robot link.
  farm_ng.perception.ApriltagRig link_tag_rig = 9;

  // the hostname and port of the RobotHALService server. e.g. "localhost:50051"
  string hal_service_address =10;
}

message CaptureRobotExtrinsicsDatasetStatus {
  oneof input_required {
    CaptureRobotExtrinsicsDatasetConfiguration  input_required_configuration = 1;
  }
  // Serialized CaptureRobotExtrinsicsDatasetResult
  farm_ng.core.Resource result = 2;

  // TODO(isherman): document
  // TODO(isherman): visualization
  //   - all frames in the configuration
  //   - workspace volume
  //   - all poses in the request queue
  //   - the last request and response pose
  //   - the last response image
  //   - latest_request_index / request_queue.length
  CaptureRobotExtrinsicsDatasetConfiguration configuration = 3;
  repeated CapturePoseRequest request_queue = 4;
  int32 latest_request_index = 5;
  CapturePoseResponse latest_response = 6;
}

message CaptureRobotExtrinsicsDatasetResult {
  // Configuration which initiated the computation of this result.
  CaptureRobotExtrinsicsDatasetConfiguration configuration=1;
  farm_ng.core.Resource dataset = 2;
}
